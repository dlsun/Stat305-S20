{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STAT 305 Notebook 8. Maximum Likelihood for Continuous Random Variables",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlsun/Stat305-S20/blob/master/colabs/notebooks/STAT_305_Notebook_8_Maximum_Likelihood_for_Continuous_Random_Variables.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqm5jy3-K7A_",
        "colab_type": "text"
      },
      "source": [
        "I encourage you to work through this notebook with a partner so that you can discuss your answers. You should meet over an application such as Discord or Zoom. One person can share their screen with this notebook open."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7FXZ6syIAUD",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "!pip install -q symbulate\n",
        "from symbulate import *\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApSnu6OPAmub",
        "colab_type": "text"
      },
      "source": [
        "# Maximum Likelihood for Continuous Random Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRT_wQMaz_fj",
        "colab_type": "text"
      },
      "source": [
        "So far, we have defined the likelihood for _discrete_ data as the p.m.f., viewed as a function of the parameter:\n",
        "\n",
        "$$ L_X(\\theta) = f_\\theta(X). $$\n",
        "\n",
        "Note that $X$ here may denote multiple observations, in which case $f_\\theta$ is the joint p.m.f."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGP8wyzw4MbR",
        "colab_type": "text"
      },
      "source": [
        "But what if the data $X$ is continuous?\n",
        "\n",
        "For continuous data, we simply define the likelihood as the p.d.f., viewed as a function of the parameter:\n",
        "\n",
        "$$ L_X(\\theta) = f_\\theta(X). $$\n",
        "\n",
        "Notice that our notation does not distinguish between p.m.f.s and p.d.f.s. In terms of maximum likelihood estimation, we handle p.m.f.s and p.d.f.s in _exactly the same_ way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH1VsSIx6Tr7",
        "colab_type": "text"
      },
      "source": [
        "# Example 3 Revisited\n",
        "\n",
        "The true weight of NB10 is an unknown number $\\mu$. It is very close to 10 grams (its weight is between 9.999 and 10.000), so we will report all of our measurements in _micrograms below 10 grams_. \n",
        "\n",
        "The 100 measurements of the weight of NB10 produced the following data (in micrograms below 10 grams)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esEOsgVY6nJn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = [409,400,406,399,402,406,401,403,401,403,398,403,407,402,401,399,400,401,405,402,408,399,399,402,399,397,407,401,399,401,403,400,410,401,407,423,406,406,402,405,405,409,399,402,407,406,413,409,404,402,404,406,407,405,411,410,410,410,401,402,404,405,392,407,406,404,403,408,404,407,412,406,409,400,408,404,401,404,408,406,408,406,401,412,393,437,418,415,404,401,401,407,412,375,409,406,398,406,403,404]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcZHGPoE6wZn",
        "colab_type": "text"
      },
      "source": [
        "We assumed that our data $X_1, ..., X_{100}$ were i.i.d. random variables from a $\\text{Normal}(\\mu, \\sigma)$ distribution. How would we estimate $\\mu$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4IaiSPSe_WH",
        "colab_type": "text"
      },
      "source": [
        "Although we do not know $\\sigma$, let's pretend that it is known. This would be a problem if the MLE of $\\mu$ turns out to depend on $\\sigma$, but it does not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LhZIoJefUER",
        "colab_type": "text"
      },
      "source": [
        "The likelihood is just the joint p.d.f. of the 100 observations, which we simplify as much as possible:\n",
        "\n",
        "\\begin{align*}\n",
        "L_X(\\mu) &= f_\\mu(409, 400, ..., 404) \\\\\n",
        "&= \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-(409 - \\mu)^2/2\\sigma^2} \\cdot \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-(400 - \\mu)^2/2\\sigma^2} \\cdot ... \\cdot \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-(404 - \\mu)^2/2\\sigma^2} \\\\\n",
        "&= \\frac{1}{\\sigma^{100} (2\\pi)^{50}} e^{-((409 - \\mu)^2 + (400 - \\mu)^2 + ... + (404 - \\mu)^2) / 2\\sigma^2}.\n",
        "\\end{align*}\n",
        "\n",
        "To make this easier to optimize, we calculate the log-likelihood.\n",
        "\n",
        "$$ \\ell(\\mu) = \\log \\frac{1}{\\sigma^{100} (2\\pi)^{50}} - \\frac{1}{2\\sigma^2} ((409 - \\mu)^2 + (400 - \\mu)^2 + ... + (404 - \\mu)^2). $$\n",
        "\n",
        "Let's graph the log-likelihood function for this data, assuming $\\sigma = 5$. Notice that the log-likelihood is in the negative thousands, meaning that the likelihood is on the order of $e^{-1000}$, which is an unbelievably small number.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V118mdn_iGtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mus = np.arange(350, 450)\n",
        "sigma = 5\n",
        "\n",
        "plt.plot(mus,\n",
        "         [-log(sigma ** 100 * (2 * pi) ** 50) \n",
        "          -sum((x - mu) ** 2 for x in data) / (2 * sigma ** 2)\n",
        "          for mu in mus],\n",
        "         \"-\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZjB3dQ5hzjE",
        "colab_type": "text"
      },
      "source": [
        "Now, at this point, we could start taking derivatives. However, we will simplify a bit further. Notice that the first term does not depend on $\\mu$, so it does not affect where the log-likelihood is maximized. The constant $\\frac{1}{2\\sigma^2}$ also does not affect where the log-likelihood is maximized, but the negative sign matters.\n",
        "\n",
        "So to calculate the MLE, we only need to maximize a part of that expression.\n",
        "\n",
        "$$ \\hat\\mu = \\underset{\\mu}{\\arg\\max} -((409 - \\mu)^2 + (400 - \\mu)^2 + ... + (404 - \\mu)^2). $$\n",
        "\n",
        "Since we are maximizing a negative, we can equivalently _minimize_ the positive expression.\n",
        "\n",
        "$$ \\hat\\mu = \\underset{\\mu}{\\arg\\min}\\  (409 - \\mu)^2 + (400 - \\mu)^2 + ... + (404 - \\mu)^2. $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3d8OJfzjuMg",
        "colab_type": "text"
      },
      "source": [
        "We know the value of $\\mu$ that minimizes this expression. In Question 1 from Notebook 3 on \"Estimating the Variance\", you showed that the value of $\\mu$ that minimizes the sum-of-squared-distances to a set of numbers is the (sample) mean of those numbers. So the MLE is \n",
        "\n",
        "$$ \\hat\\mu = \\frac{409 + 400 + ... + 404}{100} = 404.59. $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wliN8wieKHME",
        "colab_type": "text"
      },
      "source": [
        "**Question 1.** Generalize the calculation above, and derive an expression for the MLE of $\\mu$, in terms of $X_1, ..., X_n$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CekzIH0frKy2",
        "colab_type": "text"
      },
      "source": [
        "_YOUR ANSWER HERE_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eFc03GTmfp5",
        "colab_type": "text"
      },
      "source": [
        "**Question 2.** Now let's calculate the MLE of $\\sigma$. We just showed that no matter the value of $\\sigma$, $\\mu$ is maximized for $\\bar X = \\frac{1}{n} \\sum_{i=1}^n X_i$, so plug this in for $\\mu$ and maximize the expression for $\\sigma$. Does this correspond to the biased or the unbiased estimator of $\\sigma^2$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3E-656FBmfn2",
        "colab_type": "text"
      },
      "source": [
        "_YOUR ANSWER HERE_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eulPEu3tfAm",
        "colab_type": "text"
      },
      "source": [
        "# Example 6: Two Gauges\n",
        "\n",
        "You have two pressure gauges for checking tire pressure. One gauge is more accurate than the other. The more accurate gauge produces readings (in psi) from a $\\text{Normal}(\\mu, \\sigma=1)$ distribution, where $\\mu$ is the true tire pressure. The less accurate gauge produces readings (in psi) from a $\\text{Normal}(\\mu, \\sigma=2)$ distribution.\n",
        "\n",
        "You take one measurement $X$ from the more accurate gauge and an independent measurement $Y$ from the less accurate one. $X = 27$, while $Y = 29$. How should we use these measurements to estimate the true tire pressure? Should we throw away the reading from the less accurate gauge?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8fe-_7pummx",
        "colab_type": "text"
      },
      "source": [
        "**Question 3.** Write down the likelihood of $\\mu$ for this data. (The likelihood is just the joint p.d.f. of $X$ and $Y$.) Calculate the MLE of $\\mu$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IerrndnXuv60",
        "colab_type": "text"
      },
      "source": [
        "_YOUR ANSWER HERE_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf2UwVHbuyCp",
        "colab_type": "text"
      },
      "source": [
        "**Question 4.** Calculate the MSE of the MLE for estimating $\\mu$. How does it compare with the MSE of just using $X$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvlPM5lxvRet",
        "colab_type": "text"
      },
      "source": [
        "_YOUR ANSWER HERE_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV6hENDO5amD",
        "colab_type": "text"
      },
      "source": [
        "# Submission Instructions\n",
        "\n",
        "1. [Go here](https://canvas.calpoly.edu/courses/25458/groups), and add you and your partner (if applicable) to one of the STAT 305 Groups.\n",
        "2. Export this Colab notebook to PDF. Easiest way is File > Print > Save as PDF.\n",
        "3. Double check that the PDF rendered properly (i.e., nothing is cut off).\n",
        "4. Upload the PDF [to Canvas](https://canvas.calpoly.edu/courses/25458/assignments/114030). Only one of you needs to upload the PDF."
      ]
    }
  ]
}